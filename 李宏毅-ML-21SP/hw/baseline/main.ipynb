{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline for DL\r\n",
    "\r\n",
    "\r\n",
    "### 数据\r\n",
    "- 区分本地/Kaggle/Colab\r\n",
    "- 数据集导入加载\r\n",
    "- 数据预处理\r\n",
    "\r\n",
    "### 模型\r\n",
    "- Pre-Trained Model, Pre-Processing & Post-Processing\r\n",
    "- 常见模型：\r\n",
    "    - ResNet\r\n",
    "    - Transformer\r\n",
    "    - Bert\r\n",
    "    - Auto-Encoder\r\n",
    "    - GAN\r\n",
    "    - Self-Attention\r\n",
    "    - LSTM\r\n",
    "    - VAE\r\n",
    "- 常见训练手段： \r\n",
    "    - Automatic Mixed Precision\r\n",
    "    - Gradient accumulation\r\n",
    "    - Learning Rate Decay\r\n",
    "    - 手动L1,L2正则化\r\n",
    "- 常见可视化手段： \r\n",
    "    - loss-curve & acc-curve\r\n",
    "\r\n",
    "\r\n",
    "借鉴：\r\n",
    "- [深度学习框架]PyTorch常用代码段 - Jack Stark的文章 - 知乎 https://zhuanlan.zhihu.com/p/104019160\r\n",
    "\r\n",
    "- Kaggle知识点：深度学习代码规范 - 阿水的文章 - 知乎 https://zhuanlan.zhihu.com/p/399681621\r\n",
    "\r\n",
    "- 【深度学习】深度学习手写代码汇总（建议收藏，面试用） - 机器<em>学习</em>社区的文章 - 知乎 https://zhuanlan.zhihu.com/p/404749749\r\n",
    "\r\n",
    "- 一文搞定深度学习中的规范化BN,LN,IN,GN,CBN - 凡心所向素履所往的文章 - 知乎   https://zhuanlan.zhihu.com/p/115949091\r\n",
    "\r\n",
    "- 深度强化学习库的设计思想（还没写完） - 曾伊言的文章 - 知乎  https://zhuanlan.zhihu.com/p/343559335"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "config = {\r\n",
    "    'task_name': 'classifier',\r\n",
    "\r\n",
    "    'env': 'local',\r\n",
    "    # 'env': 'kaggle',\r\n",
    "    # 'env': 'colab',\r\n",
    "\r\n",
    "    'use_image': False,\r\n",
    "\r\n",
    "    'is_renew': False,\r\n",
    "    'is_train': False,\r\n",
    "    'is_valid': False,\r\n",
    "    'is_test': False,\r\n",
    "    'is_early_stop': False,\r\n",
    "    'is_do_semi': False,\r\n",
    "\r\n",
    "\r\n",
    "    'epoches' : 1,\r\n",
    "    'early_stop': 5,\r\n",
    "\r\n",
    "    'max_steps': 100000,\r\n",
    "    'train_steps': 1000,\r\n",
    "    'log_steps': 100,\r\n",
    "    'valid_steps': 100,\r\n",
    "    'test_steps': 100,\r\n",
    "    'warmup_steps': 10000,\r\n",
    "    'decay_steps': 50000,\r\n",
    "\r\n",
    "    'dataset_dir': './data/',\r\n",
    "    'train_path': './data/',\r\n",
    "    'valid_path': './data/',\r\n",
    "    'test_path': './data',\r\n",
    "    \r\n",
    "    'valid_ratio': 0.15,\r\n",
    "\r\n",
    "    'learning_rate': 1e-3,\r\n",
    "    'weight_decay_l1': 1e-4,\r\n",
    "    'weight_dacay_l2': 1e-5,\r\n",
    "\r\n",
    "    'momentum': 0.9,\r\n",
    "    'batch_size': 16,\r\n",
    "    'n_workers': 0,\r\n",
    "\r\n",
    "\r\n",
    "    'load_model_path': './checkpoint/',\r\n",
    "    'save_model_path': './checkpoint/',\r\n",
    "\r\n",
    "    'fp16_training': False,\r\n",
    "}\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import Packages\r\n",
    "import torch, os, sys, csv, json, random\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "\r\n",
    "from torch.utils.data import Dataset, Dataloader, Subset, ConcatDataset\r\n",
    "from torch.autograd import Variable\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "from torch.nn.utils.rnn import pad_sequence\r\n",
    "\r\n",
    "from tdqm.auto import tqdm\r\n",
    "\r\n",
    "if config['use_image']:\r\n",
    "    from torchvision.datasets import DatasetFolder\r\n",
    "    from PIL import Image\r\n",
    "    from torchvision.transforms import transforms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if config['env'] == 'kaggle':\r\n",
    "    !pip install transforms\r\n",
    "\r\n",
    "    task_path = '/kaggle/working/' + config['task_name']\r\n",
    "    if not os.path.exists(task_path):\r\n",
    "        os.makedirs(task_path)\r\n",
    "    \r\n",
    "    !pwd\r\n",
    "    !ls\r\n",
    "\r\n",
    "elif config['env'] == 'colab':\r\n",
    "    !pip install transforms\r\n",
    "\r\n",
    "    from google.drive import drive\r\n",
    "    task_path = '/content/drive/MyDrive/'+config['task_name']\r\n",
    "    if not os.path.exists(task_path):\r\n",
    "        os.makedirs(task_path)\r\n",
    "    drive.mount(task_path)\r\n",
    "\r\n",
    "    if not os.path.exists(task_path + '/data'):\r\n",
    "        !gdown \r\n",
    "        !unzip\r\n",
    "\r\n",
    "\r\n",
    "    !pwd\r\n",
    "    !ls\r\n",
    "\r\n",
    "\r\n",
    "import transforms\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Common Functions\r\n",
    "def refresh_gpu_cache():\r\n",
    "    return torch.cuda.empty_cache()\r\n",
    "\r\n",
    "\r\n",
    "def random_seed(seed=0):\r\n",
    "    np.random.seed(seed)\r\n",
    "    torch.manual_seed(seed)\r\n",
    "    torch.cuda.manual_seed_all(seed)\r\n",
    "\r\n",
    "    torch.backends.cudnn.deterministic = True\r\n",
    "    torch.backends.cudnn.benchmark = False\r\n",
    "\r\n",
    "\r\n",
    "def get_device():\r\n",
    "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "random_seed(0)\r\n",
    "device = get_device()\r\n",
    "\r\n",
    "if config['fp16_training'] and config['env'] != 'local':\r\n",
    "    !pip install accelerate==0.2.0:\r\n",
    "    from accelerate import Accelerator\r\n",
    "    accelerator = Accelerator(fp16=True)\r\n",
    "    device = accelerator.device"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# DataSet and Dataloader\r\n",
    "class MyDataset(Dataset):\r\n",
    "    def __init__(self, path=None, data=None, label=None, \r\n",
    "                transform=None, transform_flag=False, mode='train',\r\n",
    "                func=None):\r\n",
    "        \"\"\"\r\n",
    "        args: \r\n",
    "            path:    dataset path\r\n",
    "            X:       data\r\n",
    "            y:       label\r\n",
    "            in_dim:  input dim\r\n",
    "            out_dim: output dim\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        super(MyDataset, self).__init__()\r\n",
    "\r\n",
    "        assert (path is None and data is None ), \"Data path and Data are both None\"\r\n",
    "\r\n",
    "        \r\n",
    "        self.data_dir = path\r\n",
    "        self.data = data\r\n",
    "        self.label = label\r\n",
    "\r\n",
    "        self.transform = transform\r\n",
    "        self.mode = mode\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        if \r\n",
    "        if mode == 'train':\r\n",
    "            \r\n",
    "            return self.data[idx], self.label[idx]\r\n",
    "        elif mode == 'valid':\r\n",
    "            \r\n",
    "            return self.data[idx], self.label[idx]\r\n",
    "        else:\r\n",
    "            \r\n",
    "            return self.data[idx]\r\n",
    "\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.data)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'pwd' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "72abe702466f9e24594ae58f080cb48b788abb39b6aa2286cc2679fe3ac90feb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}